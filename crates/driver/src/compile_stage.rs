#[derive(Clone, Copy, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub enum CompileStage {
    /// When the compiler encounters a module definition (e.g. `mod foo;`), it checks
    /// whether the corresponding file (e.g. `src/foo.sdg`) exists. If the file is
    /// found, the module enters this stage.
    Load,

    /// The compiler reads the source code as a string and converts it to a sequence
    /// of tokens.
    Lex,

    /// It creates an AST from the tokens.
    Parse,

    /// This stage performs per-file name resolution. It also does some lowerings
    /// that can be done per-file.
    /// Since this stage is processed per-file, it can run in parallel and can be
    /// cached for incremental compilation (you can reuse hir if the file hasn't
    /// changed).
    Hir,

    /// In this stage, the compiler performs name resolution across file
    /// boundaries. This stage requires all files' HIR to be loaded into memory
    /// simultaneously, so it cannot be parallelized.
    InterHir,

    /// MIR is like HIR, but a few more lowerings (that requires information from
    /// InterHir) are done. MIR is generated per-file, so it can be parallelized.
    /// But because it depends on InterHir, it cannot be cached like HIRs.
    ///
    /// After this, we're ready for type analysis.
    Mir,

    /// In this stage, the compiler performs type analysis, which includes both
    /// type inference and type checking. It also runs the poly-generic solver and
    /// performs monomorphization of generic types and functions.
    ///
    /// Since this stage needs all files' MIR to be available, it cannot be
    /// parallelized.
    InterMir,

    /// This stage handles lowering that requires type information. 
    /// It lowers match expressions to decision trees. It also lowers `Field::Name`s
    /// to `Field::Index`.
    PostMir,

    /// Now that every lowering and checking are complete, it can do optimizations.
    /// It runs in parallel, but sometimes it needs items in other modules (e.g. when inlining).
    /// So, the compiler creates a global hash map for functions, and each worker reads/writes
    /// the hash map with locks.
    MirOptimize,

    /// The Bytecode stage converts the optimized MIR from a tree structure into a
    /// linear sequence of bytecode instructions for a stack machine.
    /// The generated bytecode can be either interpreted directly or further lowered
    /// to assembly or other target languages (WIP).
    ///
    /// This stage generates bytecodes per module, so it runs in parallel.
    ///
    /// This stage does not generate any errors or warnings.
    Bytecode,

    /// This stage does per-module bytecode optimization in parallel.
    BytecodeOptimize,

    /// Currently, only 1 backend is available: Backend::Bytecode.
    CodeGen,
}

pub const COMPILE_STAGES: [CompileStage; 12] = [
    CompileStage::Load,
    CompileStage::Lex,
    CompileStage::Parse,
    CompileStage::Hir,
    CompileStage::InterHir,
    CompileStage::Mir,
    CompileStage::InterMir,
    CompileStage::PostMir,
    CompileStage::MirOptimize,
    CompileStage::Bytecode,
    CompileStage::BytecodeOptimize,
    CompileStage::CodeGen,
];

impl CompileStage {
    pub fn is_parallel(&self) -> bool {
        match self {
            CompileStage::Load => true,
            CompileStage::Lex => true,
            CompileStage::Parse => true,
            CompileStage::Hir => true,
            CompileStage::InterHir => false,
            CompileStage::Mir => true,
            CompileStage::InterMir => false,
            CompileStage::PostMir => true,
            CompileStage::MirOptimize => true,
            CompileStage::Bytecode => true,
            CompileStage::BytecodeOptimize => true,
            CompileStage::CodeGen => false,
        }
    }
}
